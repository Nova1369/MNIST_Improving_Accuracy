{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4dab4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Training Run 1\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8560\\3050234883.py:100: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size), epochs=epochs,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "937/937 [==============================] - 85s 89ms/step - loss: 0.3061 - accuracy: 0.9106 - val_loss: 0.0379 - val_accuracy: 0.9888 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "937/937 [==============================] - 83s 89ms/step - loss: 0.1090 - accuracy: 0.9670 - val_loss: 0.0472 - val_accuracy: 0.9846 - lr: 9.0000e-04\n",
      "Epoch 3/10\n",
      "937/937 [==============================] - 86s 92ms/step - loss: 0.0859 - accuracy: 0.9743 - val_loss: 0.0275 - val_accuracy: 0.9909 - lr: 8.1000e-04\n",
      "Epoch 4/10\n",
      "937/937 [==============================] - 84s 90ms/step - loss: 0.0722 - accuracy: 0.9782 - val_loss: 0.0241 - val_accuracy: 0.9921 - lr: 7.2900e-04\n",
      "Epoch 5/10\n",
      "937/937 [==============================] - 83s 89ms/step - loss: 0.0609 - accuracy: 0.9817 - val_loss: 0.0212 - val_accuracy: 0.9926 - lr: 6.5610e-04\n",
      "Epoch 6/10\n",
      "937/937 [==============================] - 87s 93ms/step - loss: 0.0517 - accuracy: 0.9838 - val_loss: 0.0235 - val_accuracy: 0.9934 - lr: 5.9049e-04\n",
      "Epoch 7/10\n",
      "937/937 [==============================] - 84s 90ms/step - loss: 0.0461 - accuracy: 0.9860 - val_loss: 0.0187 - val_accuracy: 0.9937 - lr: 5.3144e-04\n",
      "Epoch 8/10\n",
      "937/937 [==============================] - 86s 91ms/step - loss: 0.0448 - accuracy: 0.9864 - val_loss: 0.0205 - val_accuracy: 0.9934 - lr: 4.7830e-04\n",
      "Epoch 9/10\n",
      "937/937 [==============================] - 85s 91ms/step - loss: 0.0396 - accuracy: 0.9881 - val_loss: 0.0148 - val_accuracy: 0.9951 - lr: 4.3047e-04\n",
      "Epoch 10/10\n",
      "937/937 [==============================] - 84s 89ms/step - loss: 0.0350 - accuracy: 0.9892 - val_loss: 0.0150 - val_accuracy: 0.9949 - lr: 3.8742e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.49%\n",
      "Training Run 2\n",
      "Epoch 1/10\n",
      "937/937 [==============================] - 85s 89ms/step - loss: 0.2950 - accuracy: 0.9139 - val_loss: 0.0456 - val_accuracy: 0.9852 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "937/937 [==============================] - 87s 93ms/step - loss: 0.1077 - accuracy: 0.9674 - val_loss: 0.0440 - val_accuracy: 0.9856 - lr: 9.0000e-04\n",
      "Epoch 3/10\n",
      "937/937 [==============================] - 91s 97ms/step - loss: 0.0854 - accuracy: 0.9745 - val_loss: 0.0338 - val_accuracy: 0.9888 - lr: 8.1000e-04\n",
      "Epoch 4/10\n",
      "937/937 [==============================] - 88s 94ms/step - loss: 0.0688 - accuracy: 0.9789 - val_loss: 0.0298 - val_accuracy: 0.9895 - lr: 7.2900e-04\n",
      "Epoch 5/10\n",
      "937/937 [==============================] - 90s 96ms/step - loss: 0.0631 - accuracy: 0.9816 - val_loss: 0.0264 - val_accuracy: 0.9918 - lr: 6.5610e-04\n",
      "Epoch 6/10\n",
      "937/937 [==============================] - 92s 98ms/step - loss: 0.0531 - accuracy: 0.9843 - val_loss: 0.0353 - val_accuracy: 0.9900 - lr: 5.9049e-04\n",
      "Epoch 7/10\n",
      "937/937 [==============================] - 88s 94ms/step - loss: 0.0465 - accuracy: 0.9854 - val_loss: 0.0200 - val_accuracy: 0.9926 - lr: 5.3144e-04\n",
      "Epoch 8/10\n",
      "937/937 [==============================] - 87s 93ms/step - loss: 0.0453 - accuracy: 0.9866 - val_loss: 0.0208 - val_accuracy: 0.9939 - lr: 4.7830e-04\n",
      "Epoch 9/10\n",
      "937/937 [==============================] - 90s 96ms/step - loss: 0.0418 - accuracy: 0.9871 - val_loss: 0.0154 - val_accuracy: 0.9944 - lr: 4.3047e-04\n",
      "Epoch 10/10\n",
      "937/937 [==============================] - 87s 93ms/step - loss: 0.0362 - accuracy: 0.9890 - val_loss: 0.0224 - val_accuracy: 0.9929 - lr: 3.8742e-04\n",
      "Accuracy: 99.29%\n",
      "Training Run 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "937/937 [==============================] - 92s 95ms/step - loss: 0.2979 - accuracy: 0.9123 - val_loss: 0.0409 - val_accuracy: 0.9865 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "937/937 [==============================] - 92s 99ms/step - loss: 0.1063 - accuracy: 0.9681 - val_loss: 0.0244 - val_accuracy: 0.9925 - lr: 9.0000e-04\n",
      "Epoch 3/10\n",
      "937/937 [==============================] - 99s 106ms/step - loss: 0.0816 - accuracy: 0.9758 - val_loss: 0.0733 - val_accuracy: 0.9786 - lr: 8.1000e-04\n",
      "Epoch 4/10\n",
      "937/937 [==============================] - 91s 97ms/step - loss: 0.0671 - accuracy: 0.9795 - val_loss: 0.0241 - val_accuracy: 0.9917 - lr: 7.2900e-04\n",
      "Epoch 5/10\n",
      "937/937 [==============================] - 90s 96ms/step - loss: 0.0623 - accuracy: 0.9808 - val_loss: 0.0318 - val_accuracy: 0.9913 - lr: 6.5610e-04\n",
      "Epoch 6/10\n",
      "937/937 [==============================] - 91s 97ms/step - loss: 0.0540 - accuracy: 0.9835 - val_loss: 0.0260 - val_accuracy: 0.9919 - lr: 5.9049e-04\n",
      "Epoch 7/10\n",
      "937/937 [==============================] - 92s 98ms/step - loss: 0.0497 - accuracy: 0.9855 - val_loss: 0.0190 - val_accuracy: 0.9937 - lr: 5.3144e-04\n",
      "Epoch 8/10\n",
      "937/937 [==============================] - 90s 96ms/step - loss: 0.0434 - accuracy: 0.9871 - val_loss: 0.0207 - val_accuracy: 0.9934 - lr: 4.7830e-04\n",
      "Epoch 9/10\n",
      "937/937 [==============================] - 89s 95ms/step - loss: 0.0422 - accuracy: 0.9872 - val_loss: 0.0130 - val_accuracy: 0.9960 - lr: 4.3047e-04\n",
      "Epoch 10/10\n",
      "937/937 [==============================] - 95s 102ms/step - loss: 0.0368 - accuracy: 0.9890 - val_loss: 0.0185 - val_accuracy: 0.9933 - lr: 3.8742e-04\n",
      "Accuracy: 99.33%\n",
      "Training Run 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "937/937 [==============================] - 97s 99ms/step - loss: 0.2957 - accuracy: 0.9137 - val_loss: 0.0431 - val_accuracy: 0.9863 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "937/937 [==============================] - 83s 89ms/step - loss: 0.1108 - accuracy: 0.9671 - val_loss: 0.0273 - val_accuracy: 0.9907 - lr: 9.0000e-04\n",
      "Epoch 3/10\n",
      "937/937 [==============================] - 83s 88ms/step - loss: 0.0858 - accuracy: 0.9741 - val_loss: 0.0463 - val_accuracy: 0.9849 - lr: 8.1000e-04\n",
      "Epoch 4/10\n",
      "937/937 [==============================] - 85s 91ms/step - loss: 0.0699 - accuracy: 0.9789 - val_loss: 0.0338 - val_accuracy: 0.9896 - lr: 7.2900e-04\n",
      "Epoch 5/10\n",
      "937/937 [==============================] - 88s 94ms/step - loss: 0.0610 - accuracy: 0.9817 - val_loss: 0.0178 - val_accuracy: 0.9936 - lr: 6.5610e-04\n",
      "Epoch 6/10\n",
      "937/937 [==============================] - 86s 92ms/step - loss: 0.0568 - accuracy: 0.9825 - val_loss: 0.0155 - val_accuracy: 0.9955 - lr: 5.9049e-04\n",
      "Epoch 7/10\n",
      "937/937 [==============================] - 88s 94ms/step - loss: 0.0475 - accuracy: 0.9860 - val_loss: 0.0189 - val_accuracy: 0.9938 - lr: 5.3144e-04\n",
      "Epoch 8/10\n",
      "937/937 [==============================] - 85s 91ms/step - loss: 0.0428 - accuracy: 0.9868 - val_loss: 0.0168 - val_accuracy: 0.9945 - lr: 4.7830e-04\n",
      "Epoch 9/10\n",
      "937/937 [==============================] - 84s 89ms/step - loss: 0.0392 - accuracy: 0.9882 - val_loss: 0.0205 - val_accuracy: 0.9940 - lr: 4.3047e-04\n",
      "Epoch 10/10\n",
      "937/937 [==============================] - 87s 93ms/step - loss: 0.0373 - accuracy: 0.9890 - val_loss: 0.0147 - val_accuracy: 0.9952 - lr: 3.8742e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.52%\n",
      "Training Run 5\n",
      "Epoch 1/10\n",
      "937/937 [==============================] - 88s 92ms/step - loss: 0.2975 - accuracy: 0.9135 - val_loss: 0.0673 - val_accuracy: 0.9799 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "937/937 [==============================] - 86s 92ms/step - loss: 0.1076 - accuracy: 0.9679 - val_loss: 0.0410 - val_accuracy: 0.9875 - lr: 9.0000e-04\n",
      "Epoch 3/10\n",
      "937/937 [==============================] - 84s 90ms/step - loss: 0.0844 - accuracy: 0.9741 - val_loss: 0.0266 - val_accuracy: 0.9920 - lr: 8.1000e-04\n",
      "Epoch 4/10\n",
      "937/937 [==============================] - 88s 94ms/step - loss: 0.0690 - accuracy: 0.9792 - val_loss: 0.0342 - val_accuracy: 0.9899 - lr: 7.2900e-04\n",
      "Epoch 5/10\n",
      "937/937 [==============================] - 83s 89ms/step - loss: 0.0584 - accuracy: 0.9833 - val_loss: 0.0193 - val_accuracy: 0.9930 - lr: 6.5610e-04\n",
      "Epoch 6/10\n",
      "937/937 [==============================] - 84s 89ms/step - loss: 0.0510 - accuracy: 0.9846 - val_loss: 0.0200 - val_accuracy: 0.9940 - lr: 5.9049e-04\n",
      "Epoch 7/10\n",
      "937/937 [==============================] - 85s 90ms/step - loss: 0.0498 - accuracy: 0.9852 - val_loss: 0.0183 - val_accuracy: 0.9932 - lr: 5.3144e-04\n",
      "Epoch 8/10\n",
      "937/937 [==============================] - 83s 89ms/step - loss: 0.0452 - accuracy: 0.9863 - val_loss: 0.0155 - val_accuracy: 0.9943 - lr: 4.7830e-04\n",
      "Epoch 9/10\n",
      "937/937 [==============================] - 84s 90ms/step - loss: 0.0384 - accuracy: 0.9884 - val_loss: 0.0241 - val_accuracy: 0.9923 - lr: 4.3047e-04\n",
      "Epoch 10/10\n",
      "937/937 [==============================] - 86s 92ms/step - loss: 0.0362 - accuracy: 0.9893 - val_loss: 0.0141 - val_accuracy: 0.9955 - lr: 3.8742e-04\n",
      "Accuracy: 99.55%\n",
      "Mean Accuracy: 0.9943600058555603\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            zoom_range = 0.1, # Randomly zoom image \n",
    "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=False,  # randomly flip images\n",
    "            vertical_flip=False)  # randomly flip images\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "#defining these prior to model to increase readability and debugging\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"Training Run {i+1}\")\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=1, padding='same', data_format='channels_last',\n",
    "                         input_shape=(28,28,1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=1, padding='same', data_format='channels_last'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid' ))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', strides=1, padding='same', data_format='channels_last'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), strides=1, padding='same', activation='relu', data_format='channels_last'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), padding='valid', strides=2))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    #Optimizer\n",
    "    optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999 )\n",
    "\n",
    "    #Compiling the model\n",
    "    model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    #for our case LearningRateScheduler will work great\n",
    "    reduce_lr = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)\n",
    "\n",
    "    #left out early_stopping parameter as it gets better accuracy\n",
    "    history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size), epochs=epochs, \n",
    "                                  validation_data=(x_test, y_test), verbose=1, \n",
    "                                  steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                                  callbacks=[reduce_lr])\n",
    "\n",
    "    # Evaluate the model\n",
    "    _, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "    accuracies.append(accuracy)\n",
    "    print(\"Accuracy: %.2f%%\" % (accuracy * 100))\n",
    "\n",
    "print(\"Mean Accuracy:\", np.mean(accuracies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9709ed01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
